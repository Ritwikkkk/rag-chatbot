{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Library Installation"
      ],
      "metadata": {
        "id": "ZSEdj3K54cSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain_community langchain langchainhub chromadb langchain-openai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_Czruji04Z9z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Key"
      ],
      "metadata": {
        "id": "2Z9RVzMDZH1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OpenAI_API_Key')"
      ],
      "metadata": {
        "id": "Bia_bPF2ZGrj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping a site to load data"
      ],
      "metadata": {
        "id": "jeFJnr4Y_ZPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(web_paths=[\"https://www.educosys.com/course/genai\"])\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHaA-0x_49IU",
        "outputId": "d59955cc-4f69-43b2-e8da-f0a63fc3d8f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'https://www.educosys.com/course/genai', 'title': 'Hands-on Generative AI Course', 'description': 'Hands-on Generative AI Course', 'language': 'en'}, page_content=\"Hands-on Generative AI CourseCoursesBundle CoursesMentorFree ContentTestimonialsFAQLogin Signup Hands-on Generative AI CourseLearn, Build, Deploy and Apply Generative AI7 weeks · 3 classes/week · 2 hrs/class + Post-class Doubt SupportAccess all Live BatchesLifetime access of RecordingsAccess Discord CommunityCode availableBuild ProjectsLearn Future-Ready TechEnroll 1Week 1Foundations of Generative AI Introduction to AI Mathematical Foundations for AI Probability, Statistics, and Linear Algebra Basics of Neural Networks Gradient Descent and Optimization Basics Architectures: Feedforward, RNN, and CNN Mini Project - Build a Simple Neural Network Using TensorFlow Mini Project - Train an Autoencoder on the MNIST Dataset2Week 2Deep Generative Models Discriminative and Generative models Generative Adversarial Networks (GANs) Variational Autoencoders (VAEs) Probabilistic Data Generation Using VAEs Four Mini Projects using TensorFlow Metrics Visualization using TensorBoard Mini Project - Implement a GAN to Generate Handwritten Digits Mini Project - Train a VAE to Generate Faces Using the CelebA Dataset3Week 3Transformers and Large Language Models RNN, LSTM Transformers Architecture Attention Mechanism: Self-Attention and Positional Encoding Major Project - Code Transformer from scratch Encoder-Decoder Framework Pretraining objectives: MLM, CLM GPT, BERT Mini Project - Sentiment Analysis Using BERT4Week 4Fine-Tuning, LangChain, LangGraph Pretraining and Fine-Tuning LoRA, QLoRA Hugging Face Fine-tuning for Tasks Like Summarization, QA LangChain Installation and Basic Setup Overview of LangChain: Prompts, Memory, Chains, Agents LangGraph: Nodes, State, StateGraph, Workflows AI Agents Mini Project - Simple Q&A Application Using LangChain5Week 5Vector Databases, RAG Vector Databases ChromaDB Applications of RAG Building RAG Pipelines with LangChain Building Frontend using Streamlit Major Project - Build End to End Chatbot like ChatGPT using Streamlit, LangGraph, ChromaDB, WebSearch Tools, Memory with LLMs Project - Build an App using Streamlit for Image Generation, Image Caption Generation, Video Caption Generation6Week 6Trending Topics MCP - Model Context Protocol Ollama Projects - Fine-Tuning using Unsloth Mixture of Experts Chain of Thoughts Deepseek Architecture7Week 7Projects, Trending Topics Distillation Diffusion Models Vision Transformers Multimodal Models CLIP Prompt EngineeringTestimonialsWe've a large community of talentsVoices of Delight: Discover what our students say about their learning journey. Real stories, real satisfaction—explore testimonials that reflect the quality, dedication, and excellence we strive to deliver.Sahitya Raj ACo-founderSreeal TechnologiesI attended Educosys live Generative AI online course, and despite not being a beginner in the field, I found it incredibly valuable for learners at all levels. The curriculum was well-structured, covering everything from basic neural networks to advanced frameworks and architectures.  One of the highlights was the transformer architecture, which was covered in remarkable depth with absolute clarity—no confusion, just a seamless understanding of self-attention, positional encoding, and how these models scale. And the way Keerti delivered it leaves a lasting impact—truly unmatched and unforgettable! Beyond the structured content, they also stretched beyond to cover the absolute latest - DeepSeek. Concepts that once felt intimidating now feel second nature.  An added bonus was the notes, which removed the overhead of excessive note-taking and allowed for more focused learning. The balance between theory and hands-on learning was perfect, making it easy to apply new knowledge in real-world projects. By the end of the course, I feel a significant boost in my confidence—whether at work, workshops, meetups, discussions, projects, or analyzing cutting-edge AI advancements.  This course is truly for everyone, whether you’re getting started or deepening your expertise in Generative AI. Highly recommended! Kudos to Keerthi and Amit for their incredible efforts in designing and delivering this course so beautifully, and for the vast amount of knowledge they have gathered and shared with us!Read moreAshish UpretiLead SDEIntelI really enjoyed the GenAI course. Coming from someone with zero knowledge on the topic, after seven weeks, I'm able to understand the magic behind GenAI. I also liked the quality of the content and how you broke down such a complex topic for easy understanding. I appreciate your patience and eagerness to clarify all the doubts. I have already enrolled in the LLD and HLD courses and am looking forward to it.Read moreSathish KrishnaBusiness Enterprise ArchitectIBMGenerative AI has been so much helpful for me in my job and my research, that this course has given me a breadth and depth of the fundamentals of every topic that we have been hearing in the trends of Computing Domain. Keerti has thought this course in a wonderful way that I can slice and dice the complexity to understand the reasoning behind each concept. I recommend this course to everyone. Kudos to Keerti and her entire team.Read moreRaman SharmaPrincipal Software EngineerOracleI found the course very helpful and well structured. It started with the very basics of neural networks, it even touched upon the maths to get a proper understanding of what's going on under the hood. Gradually progressing towards more advanced models like CNN, RNN, and then transformers was done in a steady and helpful way. The intuitions Keerti provided were very useful and make a lasting impression in your mind regarding the topic. I haven't found such intuitions and easy to understand explanations elsewhere. Taking this course has increased my confidence towards GenAI and it has given me a solid platform from where I can read more AI related blogs, whitepapers, etc. without feeling overwhelmed. It has even helped me demonstrate a POC within my team that was well received. I recommend this course to anyone starting out with GenAIRead moreSudarshan Suresh SrikantSoftware EngineerCienaKudos to the Educosys team and thanks to Keerti for making learning AI/ML easy. Starting from the basics upto advanced level with most up to date AI developments, the course instilled me with great confidence in approaching problems that could be solved with AI. Every minute detail with code was covered in-depth. I would definitely recommend taking up this course.Read moreSyed IInformation Security OfficerForm3A real game changer of a course especially when it comes to real world applications. Keerti is an amazing mentor and gets to the crux of the learning without any frills. Highly recommend.Ruthira SekarI'm Database developer/DBA, Completing the Generative AI course was an insightful experience, deepening my knowledge of Machine Learning. Keerti’s passion for teaching made complex topics easy to grasp. I highly recommend this course to anyone interested in AI and ML!Read moreAbhijit MoneSDEMentorgainI'm Database developer/DBA, Completing the Generative AI course was an insightful experience, deepening my knowledge of Machine Learning. Keerti’s passion for teaching made complex topics easy to grasp. I highly recommend this course to anyone interested in AI and ML!Read moreManika KaushikSenior Software EngineerOptum-United HealthGroupKeerti explains everything in such simple and creative manner, even difficult and huge topics became easy to understand.Frequently asked questionsIs this a Live or Recorded Course?When will the next Live batch be launched?What if I am interested in learning Live only?What are the prerequisites for the course?Is Machine Learning pre-requisite for the course?How many projects will we work on? Can I add these to resume?Is this course for freshers or for experienced people?How will you be able to cover so much in 7 weeks?What languages do we use to build the projects?Can I watch the classes only on the phone without a Laptop?Will you provide the code?Where can I ask you doubts?What language will the course be taught in?Do you have a mobile application?Can I watch the class recordings or go through notes offline?Do you provide certificate for the course?Can I get invoices for reimbursement?I have more questions, how can I reach out to you?© 2025 Copyright Educosys. All rights reserved.\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap = 200)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "-qKcLhWDBGPz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6exYxBxiBnIP",
        "outputId": "de00c5ee-0313-441c-ab7f-40918ce94431"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://www.educosys.com/course/genai', 'title': 'Hands-on Generative AI Course', 'description': 'Hands-on Generative AI Course', 'language': 'en'}, page_content='Hands-on Generative AI CourseCoursesBundle CoursesMentorFree ContentTestimonialsFAQLogin Signup Hands-on Generative AI CourseLearn, Build, Deploy and Apply Generative AI7 weeks · 3 classes/week · 2 hrs/class + Post-class Doubt SupportAccess all Live BatchesLifetime access of RecordingsAccess Discord CommunityCode availableBuild ProjectsLearn Future-Ready TechEnroll 1Week 1Foundations of Generative AI Introduction to AI Mathematical Foundations for AI Probability, Statistics, and Linear Algebra Basics of Neural Networks Gradient Descent and Optimization Basics Architectures: Feedforward, RNN, and CNN Mini Project - Build a Simple Neural Network Using TensorFlow Mini Project - Train an Autoencoder on the MNIST Dataset2Week 2Deep Generative Models Discriminative and Generative models Generative Adversarial Networks (GANs) Variational Autoencoders (VAEs) Probabilistic Data Generation Using VAEs Four Mini Projects using TensorFlow Metrics Visualization using TensorBoard Mini Project -')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np # Import numpy for potential array operations if needed, though .tolist() handles it\n",
        "\n",
        "text_chunks = [doc.page_content for doc in splits]\n",
        "metadatas = [doc.metadata for doc in splits]\n",
        "\n",
        "# 2. Load your SentenceTransformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2') # Or 'all-MiniLM-L6-v2' if you prefer\n",
        "\n",
        "# 3. Generate embeddings for your text chunks\n",
        "print(\"Generating embeddings...\")\n",
        "phrase_embeddings = model.encode(text_chunks, convert_to_numpy=True)\n",
        "print(f\"Generated {len(phrase_embeddings)} embeddings, each with dimension: {phrase_embeddings.shape[1]}\")\n",
        "print(f\"{phrase_embeddings[0][:10]}\")\n",
        "# 4. Initialize ChromaDB Client\n",
        "# For an in-memory client (good for testing/development):\n",
        "client = chromadb.Client()\n",
        "\n",
        "# 5. Create or get a collection\n",
        "collection_name = \"my_document_chunks_collection\"\n",
        "try:\n",
        "    collection = client.get_or_create_collection(name=collection_name) # get_or_create_collection is convenient\n",
        "    print(f\"Collection '{collection_name}' ready.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error getting/creating collection: {e}\")\n",
        "    # Handle specific errors if needed, e.g., if the client path is wrong\n",
        "\n",
        "ids = [f\"doc_{i}\" for i in range(len(text_chunks))]\n",
        "\n",
        "# 7. Add embeddings and data to the collection\n",
        "print(\"Adding embeddings and documents to ChromaDB...\")\n",
        "try:\n",
        "    collection.add(\n",
        "        embeddings=phrase_embeddings.tolist(),# Convert numpy array to list of lists\n",
        "        documents=text_chunks,                # The original text content\n",
        "        metadatas=metadatas,                  # The extracted metadata\n",
        "        ids=ids                               # Unique identifiers\n",
        "    )\n",
        "    print(f\"Successfully added {len(text_chunks)} chunks to the collection '{collection_name}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error adding documents to collection: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wIiggtfOg_7",
        "outputId": "e96c3fdf-7d0c-49d2-e06d-e7dd381cbf70"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings...\n",
            "Generated 11 embeddings, each with dimension: 384\n",
            "[-0.09630623 -0.08975942  0.04699757 -0.01128613 -0.02908106  0.02911405\n",
            " -0.02468756 -0.03765856 -0.10992973 -0.05269187]\n",
            "Collection 'my_document_chunks_collection' ready.\n",
            "Adding embeddings and documents to ChromaDB...\n",
            "Successfully added 11 chunks to the collection 'my_document_chunks_collection'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5cZCb49fIYn",
        "outputId": "034109c9-3cd1-4470-8189-d510c0d4d241"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.09630623, -0.08975942,  0.04699757, ...,  0.06487723,\n",
              "        -0.12483238, -0.01229357],\n",
              "       [-0.10834444, -0.06192407,  0.05941018, ...,  0.07756441,\n",
              "        -0.03659645,  0.0271165 ],\n",
              "       [-0.02639303, -0.04659655,  0.06478772, ...,  0.04558603,\n",
              "        -0.0018365 ,  0.01896166],\n",
              "       ...,\n",
              "       [-0.05776486, -0.07663081, -0.03873942, ..., -0.01104692,\n",
              "        -0.08679643,  0.00611247],\n",
              "       [-0.05165751, -0.01618834, -0.02688786, ...,  0.01069521,\n",
              "        -0.10619239,  0.01832873],\n",
              "       [-0.04477612, -0.00829121, -0.00358509, ..., -0.03145244,\n",
              "        -0.02841158, -0.03470898]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(collection.get(ids=['doc_0'], include=['embeddings','documents']))"
      ],
      "metadata": {
        "id": "wAL7_W_wb4WD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_results = collection.query(\n",
        "    query_texts=[\"What exactly is in the Gen AI course?\"], # A query text\n",
        "    n_results=2, # Number of top similar results\n",
        "    # You can also use where clauses for metadata filtering:\n",
        "    # where={\"source\": \"https://www.educosys.com/course/genai\"}\n",
        ")\n",
        "\n",
        "print(\"\\nQuery Results:\")\n",
        "if query_results and query_results['documents']:\n",
        "    for i, doc in enumerate(query_results['documents'][0]):\n",
        "        print(f\"  Result {i+1}:\")\n",
        "        print(f\"    Document: {doc}\")\n",
        "        # Note: 'distances' might not always be present depending on the query type\n",
        "        if query_results['distances'] and query_results['distances'][0]:\n",
        "            print(f\"    Distance: {query_results['distances'][0][i]}\")\n",
        "        print(f\"    Metadata: {query_results['metadatas'][0][i]}\")\n",
        "        print(f\"    ID: {query_results['ids'][0][i]}\")\n",
        "else:\n",
        "    print(\"No results found or an error occurred during query.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZmVOUk7VfUd",
        "outputId": "9c56af53-fac3-419d-a0ab-e89b60256529"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:01<00:00, 63.5MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query Results:\n",
            "  Result 1:\n",
            "    Document: in your mind regarding the topic. I haven't found such intuitions and easy to understand explanations elsewhere. Taking this course has increased my confidence towards GenAI and it has given me a solid platform from where I can read more AI related blogs, whitepapers, etc. without feeling overwhelmed. It has even helped me demonstrate a POC within my team that was well received. I recommend this course to anyone starting out with GenAIRead moreSudarshan Suresh SrikantSoftware EngineerCienaKudos to the Educosys team and thanks to Keerti for making learning AI/ML easy. Starting from the basics upto advanced level with most up to date AI developments, the course instilled me with great confidence in approaching problems that could be solved with AI. Every minute detail with code was covered in-depth. I would definitely recommend taking up this course.Read moreSyed IInformation Security OfficerForm3A real game changer of a course especially when it comes to real world applications. Keerti\n",
            "    Distance: 0.7578792572021484\n",
            "    Metadata: {'language': 'en', 'title': 'Hands-on Generative AI Course', 'source': 'https://www.educosys.com/course/genai', 'description': 'Hands-on Generative AI Course'}\n",
            "    ID: doc_7\n",
            "  Result 2:\n",
            "    Document: AI. Highly recommended! Kudos to Keerthi and Amit for their incredible efforts in designing and delivering this course so beautifully, and for the vast amount of knowledge they have gathered and shared with us!Read moreAshish UpretiLead SDEIntelI really enjoyed the GenAI course. Coming from someone with zero knowledge on the topic, after seven weeks, I'm able to understand the magic behind GenAI. I also liked the quality of the content and how you broke down such a complex topic for easy understanding. I appreciate your patience and eagerness to clarify all the doubts. I have already enrolled in the LLD and HLD courses and am looking forward to it.Read moreSathish KrishnaBusiness Enterprise ArchitectIBMGenerative AI has been so much helpful for me in my job and my research, that this course has given me a breadth and depth of the fundamentals of every topic that we have been hearing in the trends of Computing Domain. Keerti has thought this course in a wonderful way that I can slice\n",
            "    Distance: 0.7963278293609619\n",
            "    Metadata: {'title': 'Hands-on Generative AI Course', 'description': 'Hands-on Generative AI Course', 'source': 'https://www.educosys.com/course/genai', 'language': 'en'}\n",
            "    ID: doc_5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "gi3KKOzKaJCf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "  return \"\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "227DXOOTf3lP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "R2w_O-9bgIqd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\"\"\""
      ],
      "metadata": {
        "id": "Mm_0T6YVhIPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgO2XXQRhc3z",
        "outputId": "d4b629e9-3250-4604-9036-a7d6b7821697"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tU5bG_mhnkZ",
        "outputId": "5efb1592-996d-44a4-ae30-00d3bc4fdece"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.documents import Document # Important: if your format_docs expects this\n",
        "\n",
        "# 1. Define your format_docs function\n",
        "# This function typically takes a list of LangChain Document objects\n",
        "# and formats their page_content into a single string.\n",
        "def format_docs(docs: list[Document]) -> str:\n",
        "    \"\"\"\n",
        "    Combines a list of LangChain Document objects into a single string context.\n",
        "    Each document's content is separated by a double newline.\n",
        "    \"\"\"\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# 2. Set up your components (placeholders - replace with your actual objects)\n",
        "#    a. Retriever: This is crucial. It should be a LangChain Retriever object\n",
        "#       that, when invoked with a query, returns a list of relevant Document objects.\n",
        "#       Example:\n",
        "from langchain_community.vectorstores import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings # or SentenceTransformerEmbeddings\n",
        "# from chromadb import PersistentClient # or chromadb.Client()\n",
        "\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "# Assuming you've already set up your ChromaDB client and collection\n",
        "# client = PersistentClient(path=\"./chroma_db_data\")\n",
        "\n",
        "vectorstore = Chroma(\n",
        "    client=client,\n",
        "    collection_name=\"my_document_chunks_collection\",\n",
        "    embedding_function=embedding_function # Or your SentenceTransformer embedding function\n",
        ")\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "#    b. Prompt Template: Defines the structure of your LLM input.\n",
        "#       It should have a placeholder for 'context' and 'question'.\n",
        "#       from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an AI assistant. Answer the user's question based only on the provided context. If you don't know the answer, say 'I don't know.'\\n\\nContext:\\n{context}\"),\n",
        "    (\"human\", \"Question: {question}\")\n",
        "])\n",
        "\n",
        "#    c. LLM: Your Large Language Model.\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI() # Example LLM\n",
        "# For demonstration, a simple lambda that simulates LLM response\n",
        "# llm = RunnableLambda(lambda x: {\"content\": f\"LLM Response to: {x['question']} based on context: {x['context'][:50]}...\"})\n",
        "\n",
        "\n",
        "# 3. Construct the RAG Chain using LCEL\n",
        "# The 'context' key in the input dictionary to the prompt now comes from:\n",
        "# - The 'retriever' being invoked (it receives the 'question' as input by default)\n",
        "# - The output of the retriever (a list of Documents) is then piped to 'format_docs'\n",
        "#   using RunnableLambda to make the regular Python function 'format_docs' a Runnable.\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever | RunnableLambda(format_docs),\n",
        "        \"question\": RunnablePassthrough() # Passes the original 'question' input through\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser() # Parses the LLM's output to a string\n",
        ")\n",
        "\n",
        "# 4. Invoke the chain\n",
        "# input_data = {\"question\": \"How long is the Generative AI course?\"}\n",
        "# response = rag_chain.invoke(input_data)\n",
        "# print(\"\\nFinal RAG Chain Response:\")\n",
        "# print(response)\n"
      ],
      "metadata": {
        "id": "QxkbNh02ibKx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Will I get course completion certificates?\")"
      ],
      "metadata": {
        "id": "sjzKWHiSpBQC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}